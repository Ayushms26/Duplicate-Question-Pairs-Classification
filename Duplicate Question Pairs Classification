import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, f1_score
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from gensim.models import Word2Vec
import re
from nltk.corpus import stopwords

# Load the dataset (replace with your dataset path)
df = pd.read_csv('question_pairs.csv')

# Preprocessing function to clean text data
def clean_text(text):
    text = text.lower()  # Lowercase
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords
    return text

# Apply preprocessing to both question columns
df['question1'] = df['question1'].apply(clean_text)
df['question2'] = df['question2'].apply(clean_text)

# Prepare Word2Vec embeddings
sentences = df['question1'].tolist() + df['question2'].tolist()
sentences = [sentence.split() for sentence in sentences]
w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)

# Create word embeddings for each question pair
def get_sentence_vector(sentence):
    words = sentence.split()
    vector = np.zeros(100)
    count = 0
    for word in words:
        if word in w2v_model.wv:
            vector += w2v_model.wv[word]
            count += 1
    return vector / (count + 1)  # Average the word vectors

X = np.array([np.concatenate([get_sentence_vector(q1), get_sentence_vector(q2)]) for q1, q2 in zip(df['question1'], df['question2'])])
y = df['is_duplicate'].values

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Build the ANN model
model = Sequential()
model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))
model.add(SpatialDropout1D(0.2))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))

# Evaluate the model
y_pred = model.predict(X_test)
y_pred_class = (y_pred > 0.5).astype(int)

# Calculate ROC AUC and F1 score
roc_auc = roc_auc_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred_class)

print(f"ROC AUC Score: {roc_auc:.2f}")
print(f"F1 Score: {f1:.2f}")

# Model accuracy
train_accuracy = model.evaluate(X_train, y_train, verbose=0)[1]
val_accuracy = model.evaluate(X_test, y_test, verbose=0)[1]

print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Validation Accuracy: {val_accuracy:.2f}")
